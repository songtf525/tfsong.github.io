# 决策树
- 步骤： 特征选择，决策树生成，决策树的修剪

- 决策树的工作原理
```
def createBranch():
'''
此处运用了迭代的思想。 感兴趣可以搜索 迭代 recursion， 甚至是 dynamic programing。
'''
    检测数据集中的所有数据的分类标签是否相同:
        If so return 类标签
        Else:
            寻找划分数据集的最好特征（划分之后信息熵最小，也就是信息增益最大的特征）
            划分数据集
            创建分支节点
                for 每个划分的子集
                    调用函数 createBranch （创建分支的函数）并增加返回结果到分支节点中
            return 分支节点
```

- 决策树的开发流程

  - 收集数据：可以使用任何方法。
  - 准备数据：树构造算法 (这里使用的是ID3算法，只适用于标称型数据，这就是为什么数值型数据必须离散化。 还有其他的树构造算法，比如CART)
  - 分析数据：可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期。
  - 训练算法：构造树的数据结构。
  - 测试算法：使用训练好的树计算错误率。
  - 使用算法：此步骤可以适用于任何监督学习任务，而使用决策树可以更好地理解数据的内在含义。

- 决策树的算法特点

  - 优点：计算复杂度不高，输出结果易于理解，数据缺失也能处理，处理不相关的特征
  - 缺点：容易过拟合
  - 适用数据类型：数值型和标称型
